{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade -q faster-whisper ipython-autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'ai_video_editor_sample_cropped_file.flac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 88.6 Âµs (started: 2023-12-13 16:29:34 +06:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2eb70ae30ee4d7dbe2376fd623470aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.bin:   0%|          | 0.00/75.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d271b79a06d54c559aecdb188f1a8c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocabulary.txt:   0%|          | 0.00/422k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2eec85c3aa46119512098d435ee207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/2.13M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5694fbe0f5fa4b8685af482ca5421b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-13 18:00:38.065] [ctranslate2] [thread 1847985] [warning] The compute type inferred from the saved model is float16, but the target device or backend do not support efficient float16 computation. The model weights have been automatically converted to use the float32 compute type instead.\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "model_size = \"tiny.en\"\n",
    "\n",
    "# Run on GPU with FP16\n",
    "model = WhisperModel(model_size, device=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments, info = model.transcribe(fileName, beam_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language 'en' with probability 1.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s -> 4.16s]  on some. You know, I'm, you know, certainly not COVID-19, but I'm hoping it meets our needs\n",
      "[4.16s -> 7.36s]  and I know that the executive is hoping that as well.\n",
      "[7.36s -> 11.36s]  Is there anything else that stands out to you or anything else you want to touch on from\n",
      "[11.36s -> 14.20s]  the last four years?\n",
      "[14.20s -> 20.32s]  You know, I, I, the executive understands our retention issues with support staff and APAs.\n",
      "[20.32s -> 27.60s]  So we're working on that as we speak. And so the retention issues that it's being able to,\n",
      "[27.60s -> 32.16s]  be one of career prosecutors, we want, we eventually want to have a staff, not one.\n",
      "[32.16s -> 36.40s]  We eventually need to have a staff. There's a representative of what this county is.\n",
      "[36.40s -> 39.24s]  And in the executive knows, and I think everybody knows I've been talking about it for\n",
      "[39.24s -> 44.36s]  years, that when it comes to counting for our size, we are, we are again severely under\n",
      "[44.36s -> 48.64s]  staff, but we're getting there. We're working toward that goal. As long as I see some progress,\n",
      "[48.64s -> 54.44s]  then I'm happy with the leadership that we're having. And again, he gets what we need.\n",
      "[54.44s -> 57.76s]  And when I call, he picks up the phone and returns my calls. And so, and then then\n",
      "[57.76s -> 62.96s]  addresses those concerns. And so I would like to think that he feels the same way about\n",
      "[62.96s -> 68.40s]  this office that I will address in concerns that he has. And I'm very pleased with those,\n",
      "[68.40s -> 70.04s]  with those things that have happened so far.\n",
      "[70.04s -> 73.76s]  And we're kind of having people wrap up just kind of give their assessment where Wayne\n",
      "[73.76s -> 77.64s]  County is today. If you want to say Wayne County is and then fill in kind of whatever you\n",
      "[77.64s -> 82.04s]  want to say where we are on the trajectory or the turnaround, whatever comes to mind.\n",
      "[82.04s -> 86.84s]  It sounds so cliche, it really does. But Wayne County is a place where I'm raising my children,\n",
      "[86.84s -> 96.68s]  where my office is, where our constituency is. We want it to be safe first and foremost,\n",
      "[96.68s -> 102.48s]  my overriding concern for not only myself, not only for my family, not only for my staff,\n",
      "[102.48s -> 108.76s]  but for the community that we serve is that we can be safe, a progressive place. A place\n",
      "[108.76s -> 113.40s]  is not afraid to address any issues in the criminal justice system. And at the end of the day,\n",
      "[113.40s -> 116.80s]  it's a safe place to live, work, worship and live.\n",
      "[116.80s -> 124.28s]  And one last thing I forget is that this is, I must say, the safe place to live, work, worship\n",
      "[124.28s -> 125.28s]  and play.\n",
      "[125.28s -> 129.96s]  And the one last thing I could say is I remember, you know, I came on board about two and a half years ago,\n",
      "[129.96s -> 133.24s]  I remember, we came back at what has been done in the first year or so as I'm trying to get up\n",
      "[133.24s -> 138.28s]  to speed, I remember, in his first budget he was able to give a car about a million dollars for the\n",
      "[138.28s -> 146.28s]  backlog of the Red Kid. That was it for that to occur at a time when you're making a lot of difficult\n",
      "[146.28s -> 151.00s]  financial decisions.\n",
      "[151.00s -> 157.56s]  When I first met with the CEO about when he was declaring his candidacy, and I met with him to talk\n",
      "[157.56s -> 162.28s]  about whether I was going to support him or not. And there were several things that were\n",
      "[162.28s -> 169.56s]  Dale Breckers for me. And I knew that I had to have some support for the main issues of the\n",
      "[169.56s -> 174.72s]  office. One of those main issues was we had no previous support from the previous administration\n",
      "[174.72s -> 179.80s]  for the sexual assault case that had been discovered in 2009. The others were things I've\n",
      "[179.80s -> 181.08s]  talked about already. They were...\n"
     ]
    }
   ],
   "source": [
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
